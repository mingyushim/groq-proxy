const express = require("express");
const axios = require("axios");
const cors = require("cors");

const app = express(); // ðŸ‘ˆ ì´ê²Œ ë¹ ì ¸ ìžˆì—ˆì–´!
app.use(cors());

const GROQ_API_KEY = process.env.GROQ_API_KEY;

// ë‚˜ë¨¸ì§€ ì½”ë“œ ê·¸ëŒ€ë¡œ
app.get("/chat", async (req, res) => {
  const { prompt, system, memory } = req.query;

  if (!prompt) {
    return res.status(400).json({ error: "Missing prompt" });
  }

  const systemMessage = system || "ëŠ¥ê¸€ë§žì€ í•œêµ­ì¸ ì¹œêµ¬ì²˜ëŸ¼ ëŒ€ë‹µí•´ì¤˜";
  const memoryList = memory ? decodeURIComponent(memory).split("|") : [];

  const memoryMessages = memoryList.map(text => {
    if (text.startsWith("ìœ ì €: ")) {
      return { role: "user", content: text.replace("ìœ ì €: ", "") };
    } else if (text.startsWith("ë´‡: ")) {
      return { role: "assistant", content: text.replace("ë´‡: ", "") };
    } else {
      return { role: "user", content: text };
    }
  });

  const messages = [
    { role: "system", content: systemMessage },
    ...memoryMessages,
    { role: "user", content: prompt }
  ];

  try {
    const response = await axios.post(
      "https://api.groq.com/openai/v1/chat/completions",
      {
        model: "meta-llama/llama-4-maverick-17b-128e-instruct",
        messages: messages,
        max_tokens: 100
      },
      {
        headers: {
          "Content-Type": "application/json",
          Authorization: `Bearer ${GROQ_API_KEY}`
        }
      }
    );

    const reply = response.data.choices[0].message.content.trim();
    res.json({ reply });
  } catch (error) {
    console.error("Groq API error:", error?.response?.data || error.message);
    res.status(500).json({ error: "Groq API í˜¸ì¶œ ì‹¤íŒ¨" });
  }
});

// ë§ˆì§€ë§‰ì— ì„œë²„ ì‹¤í–‰
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`âœ… Server listening on port ${PORT}`);
});
